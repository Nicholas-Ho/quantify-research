{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polygon Exploratory Data Analysis\n",
    "Exploratory Data Analysis with 10-years of Stock and ETF data from the US.\n",
    "\n",
    "This notebook targets the basic strategy concepts of algorithmic trading, namely:\n",
    "- Mean reversion\n",
    "- Trend following/Momentum trading\n",
    "- Statistical Arbitrage\n",
    "\n",
    "To that end, the following analyses will be conducted:\n",
    "- Moving average (simple and exponential)\n",
    "- Volatility measures (ATR/Standard Deviation) across equities and time\n",
    "- Age of equities\n",
    "- Correlation between equities\n",
    "\n",
    "2D-plots can be plotted as heat maps\n",
    "\n",
    "The effect of significant dates/events can also be studied (eg holidays, ex-dividends, splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "\n",
    "dir_name = \"data/10year_1hourcandle_us_etf_stock/data/\"\n",
    "\n",
    "# From API documentation\n",
    "column_def = {\n",
    "    \"o\": \"open_price\",\n",
    "    \"c\": \"close_price\",\n",
    "    \"h\": \"high_price\",\n",
    "    \"l\": \"low_price\",\n",
    "    \"n\": \"num_transactions\", # number of transactions in window\n",
    "    \"t\": \"timestamp\", # Unix Milliseconds\n",
    "    \"v\": \"volume\",\n",
    "    \"vw\": \"vol_weighted_average_price\"\n",
    "}\n",
    "\n",
    "etf_dfs = []\n",
    "\n",
    "for filename in glob.glob(os.path.join(dir_name, \"*.csv\")):\n",
    "    if os.path.isfile:\n",
    "        df = pd.read_csv(filename, header=0, delimiter=',', index_col=0)\n",
    "\n",
    "        ticker = filename.split('\\\\')[-1][:-4]\n",
    "        df['ticker'] = ticker\n",
    "        \n",
    "        df.rename(column_def, inplace=True, axis=1)\n",
    "\n",
    "        etf_dfs.append(df)\n",
    "    \n",
    "\n",
    "agg_df = pd.concat(etf_dfs, axis=0, join='outer', ignore_index=True)\n",
    "\n",
    "print(agg_df.shape[0])\n",
    "agg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're not too concerned about the volume weighted average price or the number of transactions, so we move on.\n",
    "\n",
    "It will be easier to deal with the individual DataFrames, so we will use the `etf_dfs` list of DataFrames for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving Averages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First calculate the moving averages. Each entry is assumed to be a day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple moving average\n",
    "def sma(df):\n",
    "    periods = (5, 10, 20, 50, 100, 200)\n",
    "    for period in periods:\n",
    "        df[f'{period:.0f}_day_sma'] = df['close_price'].rolling(period).mean()\n",
    "    return df\n",
    "\n",
    "for i in range(len(etf_dfs)):\n",
    "    etf_dfs[i] = sma(etf_dfs[i])\n",
    "\n",
    "etf_dfs[0].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponential moving average\n",
    "def ema(df):\n",
    "    smoothing = 2\n",
    "\n",
    "    periods = (12, 26, 50, 200)\n",
    "    close = df['close_price'].to_numpy() # Convert to numpy array\n",
    "\n",
    "    for period in periods:\n",
    "        # continue if the period exceeds the length of the data\n",
    "        if period > df.shape[0]:\n",
    "            continue\n",
    "\n",
    "        ema = np.empty(df.shape[0])\n",
    "\n",
    "        # The first <period> days should be empty\n",
    "        for i in range(period):\n",
    "            ema[i] = np.NaN\n",
    "\n",
    "        # Calculate <period>+1 EMA using the SMA of the first <period> days\n",
    "        initial_sma = np.mean(close[:period])\n",
    "        ema[period] = (close[period] * (smoothing / (1+period))) + (initial_sma * (1 - (smoothing / (1+period))))\n",
    "\n",
    "        # Calculate the rest of the EMAs\n",
    "        for i in range(period+1, len(close)):\n",
    "            ema[i] = (close[i] * (smoothing / (1+period))) + (ema[i-1] * (1 - (smoothing / (1+period))))\n",
    "        df[f'{period:.0f}_day_ema'] = pd.Series(ema)\n",
    "\n",
    "    return df\n",
    "\n",
    "for i in range(len(etf_dfs)):\n",
    "    etf_dfs[i] = ema(etf_dfs[i])\n",
    "\n",
    "etf_dfs[0].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Visualisation\n",
    "fig, axs = plt.subplots(4, 2)\n",
    "\n",
    "for i in range(len(etf_dfs)):\n",
    "    try:\n",
    "        ema_12 = etf_dfs[i][\"12_day_ema\"]\n",
    "        ema_200 = etf_dfs[i][\"200_day_ema\"]\n",
    "        ts = etf_dfs[i][\"timestamp\"].map(lambda x: datetime.datetime.fromtimestamp(x/1000))\n",
    "    except:\n",
    "        # Less than 200 days old (or less than 12 days old, but unlikely)\n",
    "        continue\n",
    "\n",
    "    row = i % 4\n",
    "    column = i // 4\n",
    "    axs[row, column].set(ylabel=\"EMA\", xlabel=\"Time\")\n",
    "    axs[row, column].set_title(etf_dfs[i].loc[0, \"ticker\"])\n",
    "    axs[row, column].plot(ts, ema_12, label=\"12 day\")\n",
    "    axs[row, column].plot(ts, ema_200, label=\"200 day\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volatility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard Deviation\n",
    "Calculate the Standard Deviation. Each entry is assumed to be a day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stddev(df, period=14):\n",
    "    df[f'{period:.0f}_day_stddev'] = df['close_price'].rolling(period).std()\n",
    "    return df\n",
    "\n",
    "for i in range(len(etf_dfs)):\n",
    "    etf_dfs[i] = stddev(etf_dfs[i])\n",
    "\n",
    "etf_dfs[0].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Visualisation\n",
    "fig, axs = plt.subplots(4, 2)\n",
    "\n",
    "for i in range(len(etf_dfs)):\n",
    "    try:\n",
    "        stddev = etf_dfs[i][\"14_day_stddev\"]\n",
    "        ts = etf_dfs[i][\"timestamp\"].map(lambda x: datetime.datetime.fromtimestamp(x/1000))\n",
    "    except:\n",
    "        # Less than 14 days old\n",
    "        continue\n",
    "\n",
    "    row = i % 4\n",
    "    column = i // 4\n",
    "    axs[row, column].set(ylabel=\"EMA\", xlabel=\"Time\")\n",
    "    axs[row, column].set_title(etf_dfs[i].loc[0, \"ticker\"])\n",
    "    axs[row, column].plot(ts, stddev, label=\"12 day\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ATR\n",
    "Calculate the ATR. Each entry is assumed to be a day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_range(high, low, yest_closing):\n",
    "    # ATR by J. Welles Wilder Jr.\n",
    "\n",
    "    # Check argument validity\n",
    "    if low > high:\n",
    "        raise Exception\n",
    "    if yest_closing == None:\n",
    "        return high-low\n",
    "    return max(high-low, abs(high-yest_closing), abs(low-yest_closing))\n",
    "\n",
    "def atr(df, period=14):\n",
    "    # For iterative speed\n",
    "    close = df['close_price'].to_numpy()\n",
    "    high = df['high_price'].to_numpy()\n",
    "    low = df['low_price'].to_numpy()\n",
    "\n",
    "    # Calculate all true ranges\n",
    "    tr = np.empty(df.shape[0])\n",
    "    tr[0] = true_range(high[0], low[0], None)\n",
    "    for i in range(1, len(tr)):\n",
    "        tr[i] = true_range(high[i], low[i], close[i-1])\n",
    "\n",
    "    # The first <period>-1 ATRs should be empty\n",
    "    atr = np.empty(df.size)\n",
    "    for i in range(period-1):\n",
    "        atr[i] = np.NaN\n",
    "\n",
    "    # Calculate the ATR of <period>\n",
    "    atr[period-1] = np.mean(tr[:period])\n",
    "\n",
    "    # Calculate the rest of the ATRs\n",
    "    for i in range(period, len(tr)):\n",
    "        atr[i] = (atr[i-1]*(period-1) + tr[i]) / period\n",
    "\n",
    "    df[f'{period:.0f}_day_atr'] = pd.Series(atr)\n",
    "    return df\n",
    "\n",
    "for i in range(len(etf_dfs)):\n",
    "    etf_dfs[i] = atr(etf_dfs[i])\n",
    "\n",
    "etf_dfs[0].head(20)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Visualisation\n",
    "fig, axs = plt.subplots(4, 2)\n",
    "\n",
    "for i in range(len(etf_dfs)):\n",
    "    try:\n",
    "        atr = etf_dfs[i][\"14_day_atr\"]\n",
    "        ts = etf_dfs[i][\"timestamp\"].map(lambda x: datetime.datetime.fromtimestamp(x/1000))\n",
    "    except:\n",
    "        # Less than 14 days old\n",
    "        continue\n",
    "\n",
    "    row = i % 4\n",
    "    column = i // 4\n",
    "    axs[row, column].set(ylabel=\"EMA\", xlabel=\"Time\")\n",
    "    axs[row, column].set_title(etf_dfs[i].loc[0, \"ticker\"])\n",
    "    axs[row, column].plot(ts, atr, label=\"12 day\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "The main takeaway is that the data is not very good. Despite being touted as 10 years of data, the data only stretches back as far as 2018 (at best; the worst offender, QIS, doesn't contain enough data points to caluclate a 200-day SMA). QIS and KRUZ are particularly poor.\n",
    "\n",
    "Furthermore, several ETFs have single-digit number of transactions a day (BFIT, BSMR, QIS). These are either in unspecified multiples (hundreds?) or the ETFs are extremely illiquid.\n",
    "\n",
    "Taking the data at face-value, the following preliminary results can be extracted:\n",
    "- BSMR and QTJA (more recently) in particular have relatively low and stable volatilites (barring a single spike) and fairly smooth variations in EMA, suggesting that they may be good candidates for mean reversion strategies.\n",
    "- BFIT, BOUT and SPSM have relatively higher volatilities and clear trends, suggesting that they may be suitable candidates for trend-following strategies.\n",
    "- TGIF has high volatility but no clear trends\n",
    "- KRUZ and QIS are too young to extract any insights\n",
    "\n",
    "However, the recommendation is to get clearer data or avoid these ETFs for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "- https://blog.udemy.com/algorithmic-trading-finance/\n",
    "- https://www.datacamp.com/tutorial/finance-python-trading\n",
    "- https://blog.quantinsti.com/exploratory-data-analysis-python/\n",
    "- https://www.sciencedirect.com/science/article/pii/S2772662223000528 (for inspiration)\n",
    "- https://www.composer.trade/learn/examples-of-best-algorithmic-strategies\n",
    "- https://www.aimspress.com/aimspress-data/dsfe/2022/2/PDF/DSFE-02-02-005.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantify",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
